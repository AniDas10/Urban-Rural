{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d80aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.KDTreeEncoding import *\n",
    "\n",
    "import xgboost as xgb\n",
    "from lib.XGBHelper import *\n",
    "from lib.XGBoost_params import *\n",
    "from lib.score_analysis import *\n",
    "\n",
    "from lib.logger import logger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "poverty_dir = '/datasets/cs255-sp22-a00-public/poverty/'\n",
    "image_dir=poverty_dir+'anon_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde316c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7cbcd0bf1262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpkl_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/Checkpoint.pk'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "pkl_file='data/Checkpoint.pk'\n",
    "D=pkl.load(open(pkl_file,'rb'))\n",
    "\n",
    "for k in D:\n",
    "    globals()[k]=D[k]\n",
    "scaling_mean=mean\n",
    "scaling_std=std\n",
    "\n",
    "bst_list=[x['bst'] for x in styled_logs[-1]['log']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d2b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model we trained for urban images only\n",
    "pkl_file='data/Checkpoint_Urban.pk'\n",
    "D=pkl.load(open(pkl_file,'rb'))\n",
    "\n",
    "for k in D:\n",
    "    globals()[k]=D[k]\n",
    "    \n",
    "scaling_mean_urban = mean\n",
    "scaling_std_urban = std\n",
    "\n",
    "bst_urban=[x['bst'] for x in styled_logs[-1]['log']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aad7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model we trained for rural images only\n",
    "pkl_file='data/Checkpoint_Rural.pk'\n",
    "D=pkl.load(open(pkl_file,'rb'))\n",
    "\n",
    "for k in D:\n",
    "    globals()[k] = D[k]\n",
    "    \n",
    "scaling_mean_rural = mean\n",
    "scaling_std_rural = std\n",
    "\n",
    "bst_rural = [x['bst'] for x in styled_logs[-1]['log']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bda86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#folds=[{'in':'country_test_reduct.csv','out':'results_country.csv'},\n",
    "#      {'in':'random_test_reduct.csv','out':'results.csv'}]\n",
    "\n",
    "folds=[{'in':'test1_test.csv','out':'test1_result.csv'},\n",
    "      {'in':'test3_test.csv','out':'test3_result.csv'}]\n",
    "\n",
    "\n",
    "for fold_i in range(len(folds)):\n",
    "    fold=folds[fold_i]\n",
    "\n",
    "    #test_csv=f'../public_tables/{fold[\"in\"]}'\n",
    "    test_csv=f'{fold[\"in\"]}'\n",
    "    test=pd.read_csv(test_csv)\n",
    "\n",
    "    out=pd.DataFrame()\n",
    "    out['filename'] = test['filename']\n",
    "    out['urban'] = test['urban']\n",
    "    out['country']=test['country']\n",
    "    out['nl_mean']=test['nl_mean']\n",
    "    #out['pred_wo_abstention']=0\n",
    "    out.set_index('filename', inplace=True)\n",
    "\n",
    "    # note the tree depth has been set here, it was not there in original code\n",
    "    Enc_data=encoded_dataset(image_dir,out,tree,depth=8,label_col='pred_wo_abstention')\n",
    "\n",
    "    data=to_DMatrix(Enc_data.data)\n",
    "    Preds=zeros([Enc_data.data.shape[0],len(bst_list)])\n",
    "    for i in range(len(bst_list)):\n",
    "        Preds[:,i]=bst_list[i].predict(data,output_margin=True)\n",
    "    Preds=(Preds-scaling_mean)/scaling_std # apply overall score scaling\n",
    "\n",
    "    _mean=np.mean(Preds,axis=1)\n",
    "    _std=np.std(Preds,axis=1)\n",
    "    \n",
    "    pred_wo_abstention=int((2*(_mean>0))-1)\n",
    "    pred_with_abstention=copy(pred_wo_abstention)\n",
    "    # we are yet to understand how to exploit the thresholds\n",
    "    pred_with_abstention[(1.25*_std)>abs(_mean)]=0\n",
    "\n",
    "    out['pred_with_abstention'] = pred_with_abstention\n",
    "    out['pred_wo_abstention'] = pred_wo_abstention\n",
    "\n",
    "    outFile=fold[\"out\"]\n",
    "    out.to_csv(outFile)\n",
    "    print('\\n\\n'+'-'*60)\n",
    "    print(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea10efcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0509 image60.npznpz\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "0\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "-1\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "0\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "-1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "data/results_country.csv\n",
      "519 image11876.npz\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8b3b8a7f2e16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mEnc_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pred_wo_abstention'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_DMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnc_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_dir, df, tree, depth, label_col)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{image_dir}/{filename}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36mencode_image\u001b[0;34m(file, tree)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mImage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mpixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36mcalc_encoding\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;34m\"\"\"calculate a log ratio encoding for a new set of vectors (=image)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdata_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mKD_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36mcalc_encoding\u001b[0;34m(self, data, full_data_size, limit, smooth)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mbelow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mabove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mabove_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mbelow_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmy_result\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mabove_results\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbelow_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36mcalc_encoding\u001b[0;34m(self, data, full_data_size, limit, smooth)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mbelow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mabove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mabove_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mbelow_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmy_result\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mabove_results\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbelow_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36mcalc_encoding\u001b[0;34m(self, data, full_data_size, limit, smooth)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mabove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mabove_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mbelow_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmy_result\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mabove_results\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbelow_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36mcalc_encoding\u001b[0;34m(self, data, full_data_size, limit, smooth)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mbelow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mabove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mabove_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mbelow_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmy_result\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mabove_results\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbelow_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36mcalc_encoding\u001b[0;34m(self, data, full_data_size, limit, smooth)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mabove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mabove_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mbelow_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmy_result\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mabove_results\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbelow_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36mcalc_encoding\u001b[0;34m(self, data, full_data_size, limit, smooth)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mbelow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mabove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mabove_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mbelow_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbelow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmy_result\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mabove_results\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbelow_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HW5/Public-CSE255-2022/notebooks/Section4-Final-Project/KDTrees+XGBoost/lib/KDTreeEncoding.py\u001b[0m in \u001b[0;36mcalc_encoding\u001b[0;34m(self, data, full_data_size, limit, smooth)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmy_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mbelow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mabove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mabove_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_data_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trying changes to the code using separate models for rural and urban \n",
    "folds=[{'in':'country_test_reduct.csv','out':'results_country.csv'},\n",
    "      {'in':'random_test_reduct.csv','out':'results.csv'}]\n",
    "\n",
    "for fold_i in range(len(folds)):\n",
    "    fold=folds[fold_i]\n",
    "\n",
    "    test_csv=f'../public_tables/{fold[\"in\"]}'\n",
    "    test=pd.read_csv(test_csv)\n",
    "\n",
    "    out=pd.DataFrame()\n",
    "    out['filename'] = test['filename']\n",
    "    out['country'] = test['country']\n",
    "    out['urban'] = test['urban']\n",
    "    out['nl_mean']=test['nl_mean']\n",
    "    out['pred_wo_abstention']=0\n",
    "    out.set_index('filename', inplace=True)\n",
    "\n",
    "    Enc_data=encoded_dataset(image_dir,out,tree,depth=8,label_col='pred_wo_abstention')\n",
    "    data=to_DMatrix(Enc_data.data)\n",
    "    \n",
    "    # all predictions for urban\n",
    "    Preds_urban=zeros([Enc_data.data.shape[0],len(bst_urban)])\n",
    "    for i in range(len(bst_urban)):\n",
    "        Preds_urban[:,i] = bst_urban[i].predict(data,output_margin=True)\n",
    "    Preds_urban = (Preds_urban-scaling_mean_urban)/scaling_std_urban # apply overall score scaling\n",
    "\n",
    "    _mean_urban = np.mean(Preds_urban,axis=1)\n",
    "    _std_urban = np.std(Preds_urban,axis=1)\n",
    "    \n",
    "    # all predictions for rural\n",
    "    Preds_rural=zeros([Enc_data.data.shape[0],len(bst_rural)])\n",
    "    for i in range(len(bst_rural)):\n",
    "        Preds_rural[:,i] = bst_rural[i].predict(data,output_margin=True)\n",
    "    Preds_rural = (Preds_rural-scaling_mean_rural)/scaling_std_rural # apply overall score scaling\n",
    "\n",
    "    _mean_rural = np.mean(Preds_rural,axis=1)\n",
    "    _std_rural = np.std(Preds_rural,axis=1)\n",
    "    \n",
    "    # combining both predictions based on urban/rural status\n",
    "    preds_wo_abstention = [0]*test.shape[0]\n",
    "    preds_with_abstention = [0]*test.shape[0]\n",
    "    for i, row in test.iterrows():\n",
    "        if row['urban']:\n",
    "            \n",
    "            preds_wo_abstention[i] = int((2*(_mean_urban[i]>0))-1)\n",
    "            preds_with_abstention[i] = 0 if (1.25*_std_urban[i])>abs(_mean_urban[i]) else preds_wo_abstention[i]\n",
    "        else:\n",
    "            preds_wo_abstention[i] = int((2*(_mean_rural[i]>0))-1)\n",
    "            preds_with_abstention[i] = 0 if (1.25*_std_rural[i])>abs(_mean_rural[i]) else preds_wo_abstention[i] \n",
    "    \n",
    "    out['pred_with_abstention'] = preds_with_abstention\n",
    "    out['pred_wo_abstention'] = preds_wo_abstention\n",
    "\n",
    "\n",
    "    outFile=f'data/{fold[\"out\"]}'\n",
    "    out.to_csv(outFile)\n",
    "    print('\\n\\n'+'-'*60)\n",
    "    print(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bff9ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 image16235.npz\n",
      "\n",
      "------------------------------------------------------------\n",
      "test1_result.csv\n",
      "999 image3695.npzz\n",
      "\n",
      "------------------------------------------------------------\n",
      "test3_result.csv\n"
     ]
    }
   ],
   "source": [
    "# trying changes to the code using separate models for rural and urban \n",
    "# with custom test sets\n",
    "folds=[{'in':'test1_test.csv','out':'test1_result.csv'},\n",
    "      {'in':'test3_test.csv','out':'test3_result.csv'}]\n",
    "\n",
    "for fold_i in range(len(folds)):\n",
    "    fold=folds[fold_i]\n",
    "\n",
    "    test_csv=f'{fold[\"in\"]}'\n",
    "    test=pd.read_csv(test_csv)\n",
    "\n",
    "    out=pd.DataFrame()\n",
    "    out['filename'] = test['filename']\n",
    "    out['country']=test['country']\n",
    "    out['nl_mean']=test['nl_mean']\n",
    "    out['pred_wo_abstention']=0\n",
    "    out.set_index('filename', inplace=True)\n",
    "\n",
    "    Enc_data=encoded_dataset(image_dir,out,tree,depth=8,label_col='pred_wo_abstention')\n",
    "    data=to_DMatrix(Enc_data.data)\n",
    "    \n",
    "    # all predictions for urban\n",
    "    Preds_urban=zeros([Enc_data.data.shape[0],len(bst_urban)])\n",
    "    for i in range(len(bst_urban)):\n",
    "        Preds_urban[:,i] = bst_urban[i].predict(data,output_margin=True)\n",
    "    Preds_urban = (Preds_urban-scaling_mean_urban)/scaling_std_urban # apply overall score scaling\n",
    "\n",
    "    _mean_urban = np.mean(Preds_urban,axis=1)\n",
    "    _std_urban = np.std(Preds_urban,axis=1)\n",
    "    \n",
    "    # all predictions for rural\n",
    "    Preds_rural=zeros([Enc_data.data.shape[0],len(bst_rural)])\n",
    "    for i in range(len(bst_rural)):\n",
    "        Preds_rural[:,i] = bst_rural[i].predict(data,output_margin=True)\n",
    "    Preds_rural = (Preds_rural-scaling_mean_rural)/scaling_std_rural # apply overall score scaling\n",
    "\n",
    "    _mean_rural = np.mean(Preds_rural,axis=1)\n",
    "    _std_rural = np.std(Preds_rural,axis=1)\n",
    "    \n",
    "    # combining both predictions based on urban/rural status\n",
    "    preds_wo_abstention = zeros([Enc_data.data.shape[0],1])\n",
    "    preds_with_abstention = zeros([Enc_data.data.shape[0],1])\n",
    "    for i, row in test.iterrows():\n",
    "        if row['urban']:\n",
    "            preds_wo_abstention[i] = (2*(_mean_urban[i]>0))-1\n",
    "            preds_with_abstention[i] = 0 if (1.25*_std_urban[i])>abs(_mean_urban[i]) else preds_wo_abstention[i] \n",
    "        else:\n",
    "            preds_wo_abstention[i] = (2*(_mean_rural[i]>0))-1\n",
    "            preds_with_abstention[i] = 0 if (1.25*_std_rural[i])>abs(_mean_rural[i]) else preds_wo_abstention[i] \n",
    "    \n",
    "    \n",
    "    out['pred_with_abstention'] = preds_with_abstention\n",
    "    out['pred_wo_abstention'] = preds_wo_abstention\n",
    "\n",
    "\n",
    "    outFile=fold[\"out\"]\n",
    "    out.to_csv(outFile)\n",
    "    print('\\n\\n'+'-'*60)\n",
    "    print(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55135f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric Score:  451\n",
      "Asymmetric Score:  474\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('test1.csv')\n",
    "df1[\"label\"] = df1[\"label\"].replace({0:-1})\n",
    "df2 = pd.read_csv('test1_result.csv')\n",
    "sym_score = 0\n",
    "asym_score = 0\n",
    "for i in range(df1.shape[0]):\n",
    "    if df1['label'][i] == df2['pred_wo_abstention'][i]:\n",
    "        sym_score += 1\n",
    "    if df1['label'][i] == df2['pred_with_abstention'][i]:\n",
    "        asym_score += 1\n",
    "    if df1['label'][i] != df2['pred_wo_abstention'][i]:\n",
    "        sym_score += -2\n",
    "    if df1['label'][i] != df2['pred_with_abstention'][i] and df2['pred_with_abstention'][i] != 0:\n",
    "        asym_score += -2\n",
    "    if df1['label'][i] != df2['pred_with_abstention'][i] and df2['pred_with_abstention'][i] == 0:\n",
    "        asym_score += 0\n",
    "        \n",
    "print(\"Symmetric Score: \", sym_score)\n",
    "print(\"Asymmetric Score: \", asym_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c088c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
