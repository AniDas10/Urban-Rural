{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a5ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from lib.KDTreeEncoding import *\n",
    "\n",
    "import xgboost as xgb\n",
    "from lib.XGBHelper import *\n",
    "from lib.XGBoost_params import *\n",
    "from lib.score_analysis import *\n",
    "\n",
    "from lib.logger import logger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9233806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up random seed, it has been set in all helper lib too\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b100edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to directories here\n",
    "poverty_dir = '/datasets/cs255-sp22-a00-public/poverty/'\n",
    "image_dir = poverty_dir + '/anon_images'\n",
    "train_table = 'public_tables/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc4b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating main dataframe and image files here\n",
    "df=pd.read_csv(train_table,index_col=0)\n",
    "df.index = df['filename']\n",
    "files=list(glob(f'{image_dir}/*.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15875577",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickled the encoded dataset, so can skip this cell if no changes are being made here (pickle again if Yes)\n",
    "## Getting features from the images in the main dataframe Enc_data using KD-trees\n",
    "## Can think of changes here to extract features from the images in a different manner\n",
    "## max_images = 610 works, but 615 will run out of memory and kernel dies\n",
    "## try changing the randomness factor here file choosing images to use for encoding\n",
    "## tree depth: (2^(tree_depth+1))+1 will decide how many columns we will be having in our encoded dataset\n",
    "## so right now 1024+1 columns will be used to encode the image data as a feature vector\n",
    "encoded_dataset_file_name = f'encoded_dataset.pk'\n",
    "encoded_tree_file_name = f'encoder_tree.pk'\n",
    "\n",
    "if os.path.isfile(encoded_dataset_file_name) and os.path.isfile(encoded_tree_file_name):\n",
    "    Enc_data = pkl.load(open(encoded_dataset_file_name,'rb'))\n",
    "    tree = pkl.load(open(encoded_tree_file_name,'rb'))\n",
    "\n",
    "else:\n",
    "    tree_depth = 8\n",
    "    train_size,tree = train_encoder(files,max_images=500,tree_depth=tree_depth)\n",
    "    Enc_data=encoded_dataset(image_dir,df,tree, depth=tree_depth, label_col='label')\n",
    "    # saving this encoded dataset and tree so that we don't have to encode it every time\n",
    "    pkl.dump(Enc_data,open(encoded_dataset_file_name,'wb'))\n",
    "    pkl.dump(tree, open(encoded_tree_file_name,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c82b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating object D to handle dataset functionalities\n",
    "# like getting subsets, bootstrapping samples, etc\n",
    "D = DataSplitter(Enc_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a87b4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new metric for our XGBoost algorithm\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "def calc_f1(predt: np.ndarray, dtrain: xgb.DMatrix):\n",
    "    preds = (predt > 0.5).astype(np.int64)\n",
    "    res = f1_score(predt>0.5, dtrain.get_label())\n",
    "    return 'f1', res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79a9fcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rural': {'max_depth': 3,\n",
       "  'eta': 0.15,\n",
       "  'verbosity': 0,\n",
       "  'feature_selector': 'shuffle',\n",
       "  'verbose_eval': 1,\n",
       "  'custom_metric': <function __main__.calc_f1(predt:numpy.ndarray, dtrain:xgboost.core.DMatrix)>,\n",
       "  'disable_default_eval_metric': True,\n",
       "  'eval_metric': ['error', 'logloss', 'auc']},\n",
       " 'Urban': {'max_depth': 3,\n",
       "  'eta': 0.3,\n",
       "  'verbosity': 0,\n",
       "  'feature_selector': 'shuffle',\n",
       "  'verbose_eval': 1,\n",
       "  'custom_metric': <function __main__.calc_f1(predt:numpy.ndarray, dtrain:xgboost.core.DMatrix)>,\n",
       "  'disable_default_eval_metric': True,\n",
       "  'eval_metric': ['error', 'logloss', 'auc']}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set all params for XGBoost here\n",
    "# param dictionary is already present in the lib.XGBoost_Params file\n",
    "# default parameters are set, can be customized and new params can also be added\n",
    "GLOBAL_PARAMS = {'Rural': {}, 'Urban': {} }\n",
    "\n",
    "\n",
    "param = GLOBAL_PARAMS['Rural']\n",
    "param['max_depth'] = 3   # depth of tree\n",
    "param['eta'] = 0.15      # shrinkage parameter\n",
    "param['verbosity'] = 0  # 0= no logging 3=max logging\n",
    "param['feature_selector'] = 'shuffle'\n",
    "param['verbose_eval'] = 1 \n",
    "param['custom_metric'] = calc_f1\n",
    "param['disable_default_eval_metric']=True\n",
    "param['eval_metric'] = ['error','logloss','auc']\n",
    "\n",
    "\n",
    "param = GLOBAL_PARAMS['Urban']\n",
    "param['max_depth'] = 3   # depth of tree\n",
    "param['eta'] = 0.3      # shrinkage parameter\n",
    "param['verbosity'] = 0  # 0= no logging 3=max logging\n",
    "param['feature_selector'] = 'shuffle'\n",
    "param['verbose_eval'] = 1 \n",
    "param['custom_metric'] = calc_f1\n",
    "param['disable_default_eval_metric']=True\n",
    "param['eval_metric'] = ['error','logloss','auc']\n",
    "\n",
    "GLOBAL_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0133c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subset has:  7443  samples\n",
      "Testing subset has:  3922  samples\n"
     ]
    }
   ],
   "source": [
    "# deciding which rows in dataset to select [True, False, False, True,.....]\n",
    "train_selector=np.random.rand(df.shape[0]) > 0.35\n",
    "# subset selecting everything which is True as Train set\n",
    "Train=D.get_subset(train_selector)\n",
    "# subset selecting everything which is False as Test set\n",
    "Test=D.get_subset(~train_selector)\n",
    "\n",
    "# checking the size of the train and test dataset train should be more\n",
    "print(\"Training subset has: \", Train.shape[0], \" samples\")\n",
    "print(\"Testing subset has: \", Test.shape[0], \" samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52723475",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-48d5469d1f5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_round'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlog200\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimple_bootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mensemble_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m styled_logs=[    \n\u001b[1;32m      5\u001b[0m     {   'log':log200,\n",
      "\u001b[0;32m~/Urban-Rural/lib/XGBHelper.py\u001b[0m in \u001b[0;36msimple_bootstrap\u001b[0;34m(model, Train, Test, param, ensemble_size, normalize)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'xgb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_DMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_xgboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lgb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_DMatrix_LGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Urban-Rural/lib/XGBHelper.py\u001b[0m in \u001b[0;36mrun_xgboost\u001b[0;34m(dtrain, dtest, param)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m#            verbose_eval=False, evals_result=evals_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     bst=xgb.train(param_D2L(cparam), dtrain, num_round, evallist,\\\n\u001b[0;32m--> 111\u001b[0;31m                 verbose_eval=param['verbose_eval'], evals_result=evals_result, feval = param['custom_metric'])\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    233\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mnboost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# check evaluation result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# do checkpoint after evaluation, in case evaluation also updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dataset name should not contain `-`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# into datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;31m# split up `test-error:0.1234`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[1;32m   1349\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param['num_round']=200\n",
    "log200=simple_bootstrap('xgb',Train,Test,param,ensemble_size=1)\n",
    "\n",
    "styled_logs=[    \n",
    "    {   'log':log200,\n",
    "        'style':['r:','r-'],\n",
    "        'label':'200 iterations',\n",
    "        'label_color':'r'\n",
    "    }\n",
    "]\n",
    "_mean,_std=plot_scores(styled_logs,title='All')\n",
    "\n",
    "pickle_file=f'data/Checkpoint.pk'\n",
    "Dump={'styled_logs':styled_logs,\n",
    "     'tree':tree,\n",
    "     'mean':_mean,\n",
    "     'std':_std}\n",
    "pkl.dump(Dump,open(pickle_file,'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98de4b11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.20901\ttrain-logloss:0.59322\ttrain-auc:0.74554\ttrain-f1:0.44927\teval-error:0.26148\teval-logloss:0.61021\teval-auc:0.69317\teval-f1:0.31983\n",
      "[1]\ttrain-error:0.20522\ttrain-logloss:0.53007\ttrain-auc:0.80390\ttrain-f1:0.55281\teval-error:0.24508\teval-logloss:0.56068\teval-auc:0.73981\teval-f1:0.47452\n",
      "[2]\ttrain-error:0.19766\ttrain-logloss:0.48973\ttrain-auc:0.83299\ttrain-f1:0.58722\teval-error:0.24590\teval-logloss:0.53233\teval-auc:0.75297\teval-f1:0.48630\n",
      "[3]\ttrain-error:0.18288\ttrain-logloss:0.46059\ttrain-auc:0.84901\ttrain-f1:0.56536\teval-error:0.24344\teval-logloss:0.51451\teval-auc:0.76611\teval-f1:0.42105\n",
      "[4]\ttrain-error:0.16638\ttrain-logloss:0.43907\ttrain-auc:0.85625\ttrain-f1:0.61218\teval-error:0.24016\teval-logloss:0.50534\teval-auc:0.76611\teval-f1:0.44821\n",
      "[5]\ttrain-error:0.16363\ttrain-logloss:0.42117\ttrain-auc:0.86659\ttrain-f1:0.62579\teval-error:0.23689\teval-logloss:0.50069\teval-auc:0.76914\teval-f1:0.46382\n",
      "[6]\ttrain-error:0.16088\ttrain-logloss:0.40724\ttrain-auc:0.87876\ttrain-f1:0.63438\teval-error:0.23689\teval-logloss:0.49809\teval-auc:0.76750\teval-f1:0.46580\n",
      "[7]\ttrain-error:0.15882\ttrain-logloss:0.39543\ttrain-auc:0.88311\ttrain-f1:0.64186\teval-error:0.23279\teval-logloss:0.49401\teval-auc:0.77182\teval-f1:0.47794\n",
      "[8]\ttrain-error:0.15676\ttrain-logloss:0.38664\ttrain-auc:0.89000\ttrain-f1:0.64706\teval-error:0.23607\teval-logloss:0.49499\teval-auc:0.77199\teval-f1:0.47253\n",
      "[9]\ttrain-error:0.15126\ttrain-logloss:0.37774\ttrain-auc:0.89651\ttrain-f1:0.65892\teval-error:0.23361\teval-logloss:0.49524\teval-auc:0.77120\teval-f1:0.46927\n",
      "[10]\ttrain-error:0.14816\ttrain-logloss:0.37172\ttrain-auc:0.90049\ttrain-f1:0.66563\teval-error:0.23361\teval-logloss:0.49378\teval-auc:0.77371\teval-f1:0.47124\n",
      "[11]\ttrain-error:0.14507\ttrain-logloss:0.36367\ttrain-auc:0.90451\ttrain-f1:0.67688\teval-error:0.23033\teval-logloss:0.51926\teval-auc:0.77548\teval-f1:0.48251\n",
      "[12]\ttrain-error:0.13785\ttrain-logloss:0.35523\ttrain-auc:0.91290\ttrain-f1:0.69319\teval-error:0.22951\teval-logloss:0.52014\teval-auc:0.77543\teval-f1:0.48718\n",
      "[13]\ttrain-error:0.13716\ttrain-logloss:0.35127\ttrain-auc:0.91539\ttrain-f1:0.69472\teval-error:0.22869\teval-logloss:0.52050\teval-auc:0.77644\teval-f1:0.49180\n",
      "[14]\ttrain-error:0.13510\ttrain-logloss:0.34618\ttrain-auc:0.91865\ttrain-f1:0.69931\teval-error:0.23279\teval-logloss:0.52142\teval-auc:0.77720\teval-f1:0.48175\n",
      "[15]\ttrain-error:0.13338\ttrain-logloss:0.34204\ttrain-auc:0.92089\ttrain-f1:0.70517\teval-error:0.23279\teval-logloss:0.52190\teval-auc:0.77762\teval-f1:0.48175\n",
      "[16]\ttrain-error:0.12891\ttrain-logloss:0.33589\ttrain-auc:0.92424\ttrain-f1:0.71440\teval-error:0.23279\teval-logloss:0.52255\teval-auc:0.77639\teval-f1:0.48175\n",
      "[17]\ttrain-error:0.12891\ttrain-logloss:0.32974\ttrain-auc:0.92648\ttrain-f1:0.71483\teval-error:0.23279\teval-logloss:0.52482\teval-auc:0.77809\teval-f1:0.48175\n",
      "[18]\ttrain-error:0.12547\ttrain-logloss:0.32561\ttrain-auc:0.92996\ttrain-f1:0.72243\teval-error:0.23443\teval-logloss:0.52407\teval-auc:0.77938\teval-f1:0.48000\n",
      "[19]\ttrain-error:0.11929\ttrain-logloss:0.31927\ttrain-auc:0.93530\ttrain-f1:0.73929\teval-error:0.22951\teval-logloss:0.52475\teval-auc:0.77933\teval-f1:0.49458\n",
      "[20]\ttrain-error:0.11585\ttrain-logloss:0.31198\ttrain-auc:0.94088\ttrain-f1:0.74832\teval-error:0.23197\teval-logloss:0.57317\teval-auc:0.78139\teval-f1:0.49374\n",
      "[21]\ttrain-error:0.11000\ttrain-logloss:0.30489\ttrain-auc:0.94481\ttrain-f1:0.76401\teval-error:0.23279\teval-logloss:0.57800\teval-auc:0.77926\teval-f1:0.49104\n",
      "[22]\ttrain-error:0.10932\ttrain-logloss:0.30010\ttrain-auc:0.94794\ttrain-f1:0.76652\teval-error:0.23115\teval-logloss:0.57917\teval-auc:0.77945\teval-f1:0.49462\n",
      "[23]\ttrain-error:0.10760\ttrain-logloss:0.29648\ttrain-auc:0.95152\ttrain-f1:0.77036\teval-error:0.23115\teval-logloss:0.60664\teval-auc:0.77648\teval-f1:0.49643\n",
      "[24]\ttrain-error:0.10760\ttrain-logloss:0.29341\ttrain-auc:0.95279\ttrain-f1:0.77103\teval-error:0.23443\teval-logloss:0.63632\teval-auc:0.77585\teval-f1:0.48929\n",
      "[25]\ttrain-error:0.10691\ttrain-logloss:0.29144\ttrain-auc:0.95434\ttrain-f1:0.77250\teval-error:0.23525\teval-logloss:0.63658\teval-auc:0.77688\teval-f1:0.48841\n",
      "[26]\ttrain-error:0.10450\ttrain-logloss:0.28810\ttrain-auc:0.95499\ttrain-f1:0.77810\teval-error:0.23689\teval-logloss:0.66353\teval-auc:0.77555\teval-f1:0.48485\n",
      "[27]\ttrain-error:0.10382\ttrain-logloss:0.28518\ttrain-auc:0.95605\ttrain-f1:0.78084\teval-error:0.23770\teval-logloss:0.66499\teval-auc:0.77411\teval-f1:0.48399\n",
      "[28]\ttrain-error:0.09660\ttrain-logloss:0.28076\ttrain-auc:0.95849\ttrain-f1:0.79770\teval-error:0.23607\teval-logloss:0.66723\teval-auc:0.77410\teval-f1:0.48754\n",
      "[29]\ttrain-error:0.09110\ttrain-logloss:0.27482\ttrain-auc:0.96374\ttrain-f1:0.81085\teval-error:0.23770\teval-logloss:0.69531\teval-auc:0.77462\teval-f1:0.48214\n",
      "[30]\ttrain-error:0.08732\ttrain-logloss:0.27158\ttrain-auc:0.96489\ttrain-f1:0.81986\teval-error:0.23607\teval-logloss:0.69487\teval-auc:0.77436\teval-f1:0.48387\n",
      "[31]\ttrain-error:0.08628\ttrain-logloss:0.26665\ttrain-auc:0.96760\ttrain-f1:0.82161\teval-error:0.23443\teval-logloss:0.72239\teval-auc:0.77303\teval-f1:0.48561\n",
      "[32]\ttrain-error:0.08732\ttrain-logloss:0.27345\ttrain-auc:0.96852\ttrain-f1:0.81909\teval-error:0.23361\teval-logloss:0.74873\teval-auc:0.77340\teval-f1:0.49016\n",
      "[33]\ttrain-error:0.08525\ttrain-logloss:0.26202\ttrain-auc:0.96969\ttrain-f1:0.82386\teval-error:0.23443\teval-logloss:0.74984\teval-auc:0.77288\teval-f1:0.48746\n",
      "[34]\ttrain-error:0.08285\ttrain-logloss:0.26790\ttrain-auc:0.97142\ttrain-f1:0.82920\teval-error:0.23689\teval-logloss:0.75411\teval-auc:0.77325\teval-f1:0.48668\n",
      "[35]\ttrain-error:0.08319\ttrain-logloss:0.26388\ttrain-auc:0.97310\ttrain-f1:0.82837\teval-error:0.23934\teval-logloss:0.75246\teval-auc:0.77407\teval-f1:0.48043\n",
      "[36]\ttrain-error:0.08250\ttrain-logloss:0.26162\ttrain-auc:0.97403\ttrain-f1:0.83003\teval-error:0.23770\teval-logloss:0.75204\teval-auc:0.77446\teval-f1:0.48582\n",
      "[37]\ttrain-error:0.07803\ttrain-logloss:0.25804\ttrain-auc:0.97543\ttrain-f1:0.84048\teval-error:0.23443\teval-logloss:0.80631\teval-auc:0.77303\teval-f1:0.49470\n",
      "[38]\ttrain-error:0.07597\ttrain-logloss:0.25685\ttrain-auc:0.97561\ttrain-f1:0.84535\teval-error:0.23361\teval-logloss:0.80609\teval-auc:0.77372\teval-f1:0.50088\n",
      "[39]\ttrain-error:0.07391\ttrain-logloss:0.25414\ttrain-auc:0.97691\ttrain-f1:0.84954\teval-error:0.23607\teval-logloss:0.80519\teval-auc:0.77372\teval-f1:0.49474\n",
      "[40]\ttrain-error:0.07219\ttrain-logloss:0.25124\ttrain-auc:0.97781\ttrain-f1:0.85376\teval-error:0.23525\teval-logloss:0.80305\teval-auc:0.77470\teval-f1:0.49561\n",
      "[41]\ttrain-error:0.07150\ttrain-logloss:0.24770\ttrain-auc:0.97896\ttrain-f1:0.85556\teval-error:0.23361\teval-logloss:0.80329\teval-auc:0.77643\teval-f1:0.49735\n",
      "[42]\ttrain-error:0.06772\ttrain-logloss:0.24500\ttrain-auc:0.97936\ttrain-f1:0.86386\teval-error:0.23770\teval-logloss:0.80474\teval-auc:0.77637\teval-f1:0.49477\n",
      "[43]\ttrain-error:0.06635\ttrain-logloss:0.24348\ttrain-auc:0.97999\ttrain-f1:0.86699\teval-error:0.23770\teval-logloss:0.80621\teval-auc:0.77463\teval-f1:0.49477\n",
      "[44]\ttrain-error:0.06463\ttrain-logloss:0.24085\ttrain-auc:0.98063\ttrain-f1:0.87070\teval-error:0.23770\teval-logloss:0.80591\teval-auc:0.77512\teval-f1:0.49477\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c722477306c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_round'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mlog200\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimple_bootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mensemble_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m styled_logs=[\n",
      "\u001b[0;32m~/Urban-Rural/lib/XGBHelper.py\u001b[0m in \u001b[0;36msimple_bootstrap\u001b[0;34m(model, Train, Test, param, ensemble_size, normalize)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'xgb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_DMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_xgboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lgb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_DMatrix_LGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Urban-Rural/lib/XGBHelper.py\u001b[0m in \u001b[0;36mrun_xgboost\u001b[0;34m(dtrain, dtest, param)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m#            verbose_eval=False, evals_result=evals_result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     bst=xgb.train(param_D2L(cparam), dtrain, num_round, evallist,\\\n\u001b[0;32m--> 111\u001b[0;31m                 verbose_eval=param['verbose_eval'], evals_result=evals_result, feval = param['custom_metric'])\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    233\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mnboost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# check evaluation result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# do checkpoint after evaluation, in case evaluation also updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dataset name should not contain `-`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# into datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;31m# split up `test-error:0.1234`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[1;32m   1349\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Only for Urban Areas now\n",
    "urban=True\n",
    "area= 'Urban' if urban else 'Rural'\n",
    "param = GLOBAL_PARAMS[area]\n",
    "selector=df['urban']==urban\n",
    "subData=D.get_subset(selector)\n",
    "subD=DataSplitter(subData)\n",
    "\n",
    "train_selector=np.random.rand(subData.shape[0]) > 0.3\n",
    "Train=subD.get_subset(train_selector)\n",
    "Test=subD.get_subset(~train_selector)\n",
    "\n",
    "param['num_round']=200\n",
    "log200=simple_bootstrap('xgb',Train,Test,param,ensemble_size=30)\n",
    "\n",
    "styled_logs=[\n",
    "    {   'log':log200,\n",
    "        'style':['b:','b-'],\n",
    "        'label':'200 iterations',\n",
    "        'label_color':'b'\n",
    "    }\n",
    "]\n",
    "\n",
    "_mean,_std=plot_scores(styled_logs,title=f'{area}Only: Split into train and test at random')\n",
    "\n",
    "pickle_file=f'data/Checkpoint_{area}.pk'\n",
    "Dump={'styled_logs':styled_logs,\n",
    "     'tree':tree,\n",
    "     'mean':_mean,\n",
    "     'std':_std}\n",
    "pkl.dump(Dump,open(pickle_file,'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ca33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "urban=False\n",
    "area= 'Urban' if urban else 'Rural'\n",
    "selector=df['urban']==urban\n",
    "subData=D.get_subset(selector)\n",
    "subD=DataSplitter(subData)\n",
    "\n",
    "train_selector=np.random.rand(subData.shape[0]) > 0.3\n",
    "Train=subD.get_subset(train_selector)\n",
    "Test=subD.get_subset(~train_selector)\n",
    "\n",
    "param['num_round']=200\n",
    "log200=simple_bootstrap('xgb',Train,Test,param,ensemble_size=30)\n",
    "\n",
    "styled_logs=[\n",
    "    {   'log':log200,\n",
    "        'style':['b:','b-'],\n",
    "        'label':'200 iterations',\n",
    "        'label_color':'b'\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "_mean,_std=plot_scores(styled_logs,title=f'{area}Only: Split into train and test at random')\n",
    "\n",
    "pickle_file=f'data/Checkpoint_{area}.pk'\n",
    "Dump={'styled_logs':styled_logs,\n",
    "     'tree':tree,\n",
    "     'mean':_mean,\n",
    "     'std':_std}\n",
    "pkl.dump(Dump,open(pickle_file,'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "parameters = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'eta':0.15,\n",
    "    'max_depth': 3,\n",
    "    'verbosity': 0,\n",
    "    'nthread': 7,\n",
    "    'num_rounds': 300,\n",
    "    'objective':'binary:logistic',\n",
    "}\n",
    "gs_xgb, X = log200[-1]['bst'], log200[-1]['dtrain'] \n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth, num_rounds, eta/100)\n",
    "    for max_depth in range(2,4)\n",
    "    for num_rounds in range(50,250,50)\n",
    "    for eta in range(10,35,5)\n",
    "]\n",
    "\n",
    "min_auc = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, num_rounds, eta in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, num_rounds={}, eta={}\".format(\n",
    "                             max_depth, num_rounds, eta))\n",
    "    # Update our parameters\n",
    "    parameters['max_depth'] = max_depth\n",
    "    parameters['num_rounds'] = num_rounds\n",
    "    parameters['eta'] = eta\n",
    "    \n",
    "    # Run CV\n",
    "    cv_results = gs_xgb.cv(\n",
    "        parameters,\n",
    "        dtrain,\n",
    "        nfold=5,\n",
    "        metrics={'auc','error','logloss'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    print(cv_results)\n",
    "    mean_auc = cv_results['test-auc-mean'].min()\n",
    "    boost_rounds = cv_results['test-auc-mean'].argmin()\n",
    "    print(\"\\tAUC {} for {} rounds\".format(mean_auc, boost_rounds))\n",
    "    if mean_auc < min_auc:\n",
    "        min_auc = mean_auc\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, AUC: {}\".format(best_params[0], best_params[1], min_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5816ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a18efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
